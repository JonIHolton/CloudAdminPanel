# <system>
#   log_level debug
# </system>

<source>
  # source for user creation logs
  @type tail
  # The folder to tail all the logs from apa
  path /app/logs/*.log
  # The tag assigned to the events read from the log
  tag user.log
  format json
  pos_file /app/pos/user_logs.pos
  read_from_head true
  refresh_interval 1m
  time_key timestamp
  time_type float
  keep_time_key true
</source>

<match user.*>
  @type copy
  # <store>
  #   @type stdout
  #   # for testing purpose
  # </store>

  <store>
    @type s3

    aws_key_id "#{ENV['AWS_ACCESS_KEY_ID']}"
    aws_sec_key "#{ENV['AWS_SECRET_ACCESS_KEY']}"
    s3_bucket "#{ENV['S3_BUCKET']}"
    s3_region "#{ENV['AWS_REGION']}"
    # store_as text
    path logs/${tag}/%Y-%m-%d
    time_slice_format %Y-%m-%dT%H-%M
    s3_object_key_format %{path}/%{time_slice}_%{hostname}_%{index}.%{file_extension}

    <format>
      @type json
    </format>
    <buffer tag,time>
      @type file
      path /app/fluentd-buffers/s3
      timekey 5s
      timekey_wait 1s
    </buffer>
  </store>

  <store>
    @type opensearch
    host "#{ENV['OPENSEARCH_HOST']}"
    scheme "https"
    port "443"
    user "#{ENV['OPENSEARCH_MASTERUSER']}"
    password "#{ENV['OPENSEARCH_PASSWORD']}"
    logstash_prefix false
    index_name "itsa_g1t1_logs"
    type_name "_doc"
    id_key "logId"

    # logstash_format true
    # logstash_prefix logs
    # type_name log
    # include_tag_key true
    # tag_key @log_name
    # buffer_type memory
    # flush_interval 5s
    # retry_limit 17
    # retry_wait 1.0
    # num_threads 4
    <buffer tag,time>
      @type file
      path /app/fluentd-buffers/elasticsearch
      timekey 5s
      timekey_wait 1s
    </buffer>
  </store>
</match>